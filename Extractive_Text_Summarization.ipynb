{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extractive Text Summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq9C/8o2P2UhhYXNSTjk5N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epic-coder97/Projects-2022/blob/main/Extractive_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization using Python\n",
        "\n",
        "\n",
        "*Nikita Dharmadhikari*\n",
        "\n",
        "\n",
        "#### Goal here is to be able to take the most important information from the source documents and produce a reader-friendly summary."
      ],
      "metadata": {
        "id": "bG1e53SQSSVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approaches for Text Summarization.\n",
        "- Extractive Summarization - dentifying important phrases or sentences from the original text and extract only these phrases\n",
        "\n",
        "- Abstractive Summarization - Generating new sentences from the original text. Generated new text might not be even present in the original text.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Here I am going to try to use Evtractive text Summarization.\n",
        "\n"
      ],
      "metadata": {
        "id": "-h4KoPjhG-jE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Get Started.\n",
        "\n",
        "## Step 1\n",
        "imporing libraries.\n",
        "There are NLTK libraries."
      ],
      "metadata": {
        "id": "2T0BUhe_ICUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aVX-QA-mSN0x"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Corpus : predefined stop words.\n",
        "- Tokenizer : Divides a word into a series of tokens."
      ],
      "metadata": {
        "id": "vJGGmwaoIQDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Sample text '''\n",
        "\n",
        "text = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.\""
      ],
      "metadata": {
        "id": "9KF3IyjIJ0dt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2\n",
        "\n",
        "Remove stop words & store them in an array.\n",
        "*Stop words are something that do not add value to the sentence. E.g. a, an, the*\n",
        "\n",
        "<p>  After that let's create a frequency table of the words. </p>\n"
      ],
      "metadata": {
        "id": "tIY1NKq-I6Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenizing the text\n",
        "stop_words = stopwords.words(\"english\")\n",
        "words = word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "7ck3rUqqI1OU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating frequency table\n",
        "freqTable = dict()\n",
        "for word in words:\n",
        "  word.lower()\n",
        "  if word in stop_words:\n",
        "    continue\n",
        "  if word in freqTable:\n",
        "    freqTable[word] =+ 1\n",
        "  else:\n",
        "    freqTable[word] = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "WWaqAYvgIOHn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3\n",
        "\n",
        "the words it contains and the frequency table, we will assign a score to each sentence.\n",
        "Then compare the sentences within the text, assign a score."
      ],
      "metadata": {
        "id": "PJ-QhyFQNJOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dictonary to keep score\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "sentenceValue = dict()\n",
        "for sentence in sentences:\n",
        "  for word, freq in freqTable.items():\n",
        "    if word in sentence.lower():\n",
        "      if sentence in sentenceValue:\n",
        "        sentenceValue[sentence] += freq\n",
        "      else:\n",
        "        sentenceValue[sentence] = freq\n",
        "\n",
        "sumValues = 0\n",
        "for sentence in sentenceValue:\n",
        "  sumValues += sentenceValue[sentence]\n",
        "\n",
        "# Avg value of a sentence from original text\n",
        "\n",
        "avg = int(sumValues/ len(sentenceValue))\n",
        "\n"
      ],
      "metadata": {
        "id": "-al45NQbNI17"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting sentence into a summary\n",
        "summary = ''\n",
        "\n",
        "for sentence in sentences:\n",
        "  if(sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * avg)):\n",
        "    summary += \" \" + sentence\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giMeqepXM9Cq",
        "outputId": "fa93dfe4-c4d9-408d-ddbc-be92d300f5e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors.\n"
          ]
        }
      ]
    }
  ]
}